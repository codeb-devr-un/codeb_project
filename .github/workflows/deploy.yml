name: Deploy WorkB CMS

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      skip_tests:
        description: 'Skip tests'
        required: false
        default: false
        type: boolean
      skip_lint:
        description: 'Skip lint checks'
        required: false
        default: false
        type: boolean
      force_deploy:
        description: 'Force deployment (skip cache)'
        required: false
        default: false
        type: boolean

env:
  APP_NAME: workb-cms
  NODE_VERSION: '20'
  PRODUCTION_URL: https://workb.net
  STAGING_URL: https://workb-staging.codeb.dev
  # Ïù¥ÎØ∏ÏßÄ Î≥¥Í¥Ä Í∞úÏàò
  MAX_IMAGE_RETENTION: 5

concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ============================================================================
  # Stage 1: ÏΩîÎìú ÌíàÏßà Í≤ÄÏÇ¨ (Î≥ëÎ†¨ Ïã§Ìñâ)
  # ============================================================================
  lint:
    name: ESLint
    runs-on: self-hosted
    if: |
      (github.event_name == 'pull_request' || github.event_name == 'push') &&
      github.event.inputs.skip_lint != 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v4
        id: cache-deps
        with:
          path: |
            node_modules
            ~/.npm
          key: deps-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            deps-${{ runner.os }}-

      - name: Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: Run ESLint
        run: npm run lint

  type-check:
    name: TypeScript Check
    runs-on: self-hosted
    if: |
      (github.event_name == 'pull_request' || github.event_name == 'push') &&
      github.event.inputs.skip_lint != 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v4
        id: cache-deps
        with:
          path: |
            node_modules
            ~/.npm
          key: deps-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            deps-${{ runner.os }}-

      - name: Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: Run Type Check
        run: npm run type-check

  # ============================================================================
  # Stage 2: ÌÖåÏä§Ìä∏
  # ============================================================================
  test:
    name: Run Tests
    runs-on: self-hosted
    needs: [lint, type-check]
    if: |
      always() &&
      (needs.lint.result == 'success' || needs.lint.result == 'skipped') &&
      (needs.type-check.result == 'success' || needs.type-check.result == 'skipped') &&
      (github.event_name == 'pull_request' || github.event_name == 'push') &&
      github.event.inputs.skip_tests != 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v4
        id: cache-deps
        with:
          path: |
            node_modules
            ~/.npm
          key: deps-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            deps-${{ runner.os }}-

      - name: Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: Run Tests
        run: npm test -- --passWithNoTests --coverage
        env:
          NODE_ENV: test

      - name: Upload Coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: coverage/
          retention-days: 7

  # ============================================================================
  # Stage 3: ÎπåÎìú Î∞è Î∞∞Ìè¨
  # ============================================================================
  build-deploy:
    name: Build & Deploy
    runs-on: self-hosted
    needs: [lint, type-check, test]
    if: |
      always() &&
      (needs.lint.result == 'success' || needs.lint.result == 'skipped') &&
      (needs.type-check.result == 'success' || needs.type-check.result == 'skipped') &&
      (needs.test.result == 'success' || needs.test.result == 'skipped') &&
      (github.event_name == 'push' || github.event_name == 'workflow_dispatch') &&
      (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    outputs:
      environment: ${{ steps.env.outputs.environment }}
      container_name: ${{ steps.vars.outputs.container_name }}
      port: ${{ steps.vars.outputs.port }}
      url: ${{ steps.vars.outputs.url }}
      image_tag: ${{ steps.vars.outputs.image_tag }}
      previous_image: ${{ steps.backup.outputs.previous_image }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Determine environment
        id: env
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
            echo "environment=production" >> $GITHUB_OUTPUT
          else
            echo "environment=staging" >> $GITHUB_OUTPUT
          fi

      - name: Set deployment variables
        id: vars
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          if [ "$ENV" = "production" ]; then
            echo "container_name=${{ env.APP_NAME }}" >> $GITHUB_OUTPUT
            echo "port=3200" >> $GITHUB_OUTPUT
            echo "image_tag=latest" >> $GITHUB_OUTPUT
            echo "url=${{ env.PRODUCTION_URL }}" >> $GITHUB_OUTPUT
            echo "memory=2g" >> $GITHUB_OUTPUT
            echo "cpus=2" >> $GITHUB_OUTPUT
          else
            echo "container_name=${{ env.APP_NAME }}-staging" >> $GITHUB_OUTPUT
            echo "port=3201" >> $GITHUB_OUTPUT
            echo "image_tag=staging" >> $GITHUB_OUTPUT
            echo "url=${{ env.STAGING_URL }}" >> $GITHUB_OUTPUT
            echo "memory=1g" >> $GITHUB_OUTPUT
            echo "cpus=1" >> $GITHUB_OUTPUT
          fi

      - name: Backup current image for rollback
        id: backup
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          BACKUP_TAG="${IMAGE_TAG}-backup-$(date +%Y%m%d%H%M%S)"

          # ÌòÑÏû¨ Ïã§Ìñâ Ï§ëÏù∏ Ïù¥ÎØ∏ÏßÄ ID Ï†ÄÏû•
          CURRENT_IMAGE=$(sudo podman inspect ${CONTAINER_NAME} --format '{{.Image}}' 2>/dev/null || echo "")

          if [ -n "$CURRENT_IMAGE" ]; then
            echo "Backing up current image: $CURRENT_IMAGE"
            sudo podman tag localhost/${{ env.APP_NAME }}:${IMAGE_TAG} localhost/${{ env.APP_NAME }}:${BACKUP_TAG} 2>/dev/null || true
            echo "previous_image=${BACKUP_TAG}" >> $GITHUB_OUTPUT
          else
            echo "No previous image to backup"
            echo "previous_image=" >> $GITHUB_OUTPUT
          fi

      - name: Fix network and dnsmasq issues
        run: |
          NETWORK_NAME="workb-network"

          echo "=== Comprehensive network cleanup ==="

          # 1. Î™®Îì† dnsmasq ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å
          echo "Killing all dnsmasq processes..."
          sudo pkill -9 dnsmasq 2>/dev/null || true
          sleep 2

          # 2. Í∏∞Ï°¥ ÎÑ§Ìä∏ÏõåÌÅ¨ ÏôÑÏ†Ñ ÏÇ≠Ï†ú
          echo "Removing existing podman networks..."
          sudo podman network rm -f ${NETWORK_NAME} 2>/dev/null || true
          sudo podman network rm -f podman 2>/dev/null || true
          sleep 1

          # 3. CNI ÏÑ§Ï†ï ÌååÏùº ÏÇ≠Ï†ú (ÌïµÏã¨! - Ïù¥ ÌååÏùºÏóê dnsname ÌîåÎü¨Í∑∏Ïù∏ ÏÑ§Ï†ïÏù¥ ÏûàÏùå)
          echo "Removing CNI configuration files..."
          sudo rm -f /etc/cni/net.d/${NETWORK_NAME}.conflist 2>/dev/null || true
          sudo rm -f /etc/cni/net.d/*${NETWORK_NAME}* 2>/dev/null || true

          # 4. CNI Îü∞ÌÉÄÏûÑ ÌååÏùº Ï†ïÎ¶¨
          echo "Cleaning up CNI runtime files..."
          sudo rm -rf /var/lib/cni/networks/${NETWORK_NAME} 2>/dev/null || true
          sudo rm -rf /var/lib/cni/networks/* 2>/dev/null || true
          sudo rm -rf /run/cni/* 2>/dev/null || true
          sudo rm -rf /var/run/cni/* 2>/dev/null || true

          # 5. dnsmasq Í¥ÄÎ†® ÌååÏùº Ï†ïÎ¶¨
          echo "Cleaning up dnsmasq files..."
          sudo rm -rf /run/containers/cni/dnsname/${NETWORK_NAME} 2>/dev/null || true
          sudo rm -rf /var/run/containers/cni/dnsname/* 2>/dev/null || true

          # 6. Ìè¨Ìä∏ 53 ÏÇ¨Ïö© ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å
          echo "Checking for processes using port 53..."
          PIDS=$(sudo lsof -ti:53 2>/dev/null | head -10) || true
          if [ -n "$PIDS" ]; then
            echo "Killing processes using port 53: $PIDS"
            echo "$PIDS" | xargs -r sudo kill -9 2>/dev/null || true
          fi
          sleep 2

          # 7. ÏÉà ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÉùÏÑ± (dnsname ÌîåÎü¨Í∑∏Ïù∏ ÎπÑÌôúÏÑ±Ìôî)
          echo "Creating network without DNS plugin..."
          sudo podman network create ${NETWORK_NAME} \
            --subnet 10.89.1.0/24 \
            --gateway 10.89.1.1 \
            --disable-dns \
            2>/dev/null || true

          # 8. ÏÉùÏÑ±Îêú CNI ÏÑ§Ï†ï ÌååÏùºÏóêÏÑú dnsname ÌîåÎü¨Í∑∏Ïù∏ Ï†úÍ±∞ ÌôïÏù∏
          echo "Verifying CNI configuration (should NOT contain dnsname):"
          sudo cat /etc/cni/net.d/${NETWORK_NAME}.conflist 2>/dev/null || echo "No conflist file"

          echo ""
          echo "Network configuration:"
          sudo podman network inspect ${NETWORK_NAME} 2>/dev/null | head -40 || true

          echo "=== Network cleanup complete ==="
          sudo podman network ls

      - name: Build image with Podman
        run: |
          echo "Building image for ${{ steps.env.outputs.environment }}..."

          BUILD_ARGS="--build-arg BUILDTIME=$(date -Iseconds)"
          BUILD_ARGS="$BUILD_ARGS --build-arg VERSION=${{ github.sha }}"
          BUILD_ARGS="$BUILD_ARGS --build-arg REVISION=${{ github.sha }}"

          # Ï∫êÏãú ÏÇ¨Ïö© Ïó¨Î∂Ä
          if [ "${{ github.event.inputs.force_deploy }}" = "true" ]; then
            BUILD_ARGS="$BUILD_ARGS --no-cache"
          else
            BUILD_ARGS="$BUILD_ARGS --layers"
          fi

          # DNS ÏÑúÎ≤Ñ Î™ÖÏãú (Ïª®ÌÖåÏù¥ÎÑà ÎÇ¥Î∂Ä DNS Ìï¥ÏÑù Î¨∏Ï†ú Ìï¥Í≤∞)
          sudo podman build \
            $BUILD_ARGS \
            --dns 8.8.8.8 \
            --dns 8.8.4.4 \
            -t localhost/${{ env.APP_NAME }}:${{ steps.vars.outputs.image_tag }} \
            -t localhost/${{ env.APP_NAME }}:${{ github.sha }} \
            .

          echo "Build complete!"
          sudo podman images | grep ${{ env.APP_NAME }}

      - name: Create Quadlet configuration
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          PORT="${{ steps.vars.outputs.port }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          ENV="${{ steps.env.outputs.environment }}"
          MEMORY="${{ steps.vars.outputs.memory }}"
          CPUS="${{ steps.vars.outputs.cpus }}"
          APP_NAME="${{ env.APP_NAME }}"

          sudo mkdir -p /etc/containers/systemd

          # Create Quadlet file
          printf '%s\n' \
            "[Unit]" \
            "Description=WorkB CMS Container (${ENV})" \
            "After=network-online.target" \
            "Wants=network-online.target" \
            "After=workb-cms-postgres.service" \
            "After=workb-cms-redis.service" \
            "" \
            "[Container]" \
            "ContainerName=${CONTAINER_NAME}" \
            "Image=localhost/${APP_NAME}:${IMAGE_TAG}" \
            "PublishPort=${PORT}:3000" \
            "Network=workb-network" \
            "Environment=NODE_ENV=${ENV}" \
            "Environment=PORT=3000" \
            "Environment=HOSTNAME=0.0.0.0" \
            "EnvironmentFile=/etc/containers/systemd/${CONTAINER_NAME}.env" \
            "AddHost=workb-cms-postgres:10.89.1.10" \
            "AddHost=workb-cms-redis:10.89.1.11" \
            "HealthCmd=curl -sf http://localhost:3000/api/health || exit 1" \
            "HealthInterval=30s" \
            "HealthTimeout=10s" \
            "HealthRetries=3" \
            "HealthStartPeriod=60s" \
            "PodmanArgs=--memory=${MEMORY} --cpus=${CPUS}" \
            "Label=app=${APP_NAME}" \
            "Label=environment=${ENV}" \
            "Label=version=${{ github.sha }}" \
            "LogDriver=journald" \
            "NoNewPrivileges=true" \
            "" \
            "[Service]" \
            "Restart=always" \
            "RestartSec=10" \
            "TimeoutStartSec=300" \
            "TimeoutStopSec=30" \
            "" \
            "[Install]" \
            "WantedBy=multi-user.target default.target" \
            | sudo tee /etc/containers/systemd/${CONTAINER_NAME}.container > /dev/null

          echo "Quadlet config created:"
          sudo cat /etc/containers/systemd/${CONTAINER_NAME}.container

      - name: Verify and sync env file
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          ENV="${{ steps.env.outputs.environment }}"
          TARGET_ENV_FILE="/etc/containers/systemd/${CONTAINER_NAME}.env"

          # Source env file location
          if [ "$ENV" = "production" ]; then
            SOURCE_ENV_FILE="/home/linuxuser/workb-cms-production.env"
          else
            SOURCE_ENV_FILE="/home/linuxuser/workb-cms-staging.env"
          fi

          # Check and copy env file
          if [ -f "$SOURCE_ENV_FILE" ]; then
            echo "Found source env file: $SOURCE_ENV_FILE"
            sudo cp "$SOURCE_ENV_FILE" "$TARGET_ENV_FILE"
            sudo chmod 600 "$TARGET_ENV_FILE"
            echo "Env file synced to: $TARGET_ENV_FILE"
            echo "Env file contents (sensitive values hidden):"
            sudo grep -v -E "(PASSWORD|SECRET|KEY|TOKEN)" "$TARGET_ENV_FILE" || true
          elif [ -f "$TARGET_ENV_FILE" ]; then
            echo "Using existing env file: $TARGET_ENV_FILE"
            if ! sudo grep -q "NEXTAUTH_SECRET" "$TARGET_ENV_FILE" 2>/dev/null; then
              echo "ERROR: NEXTAUTH_SECRET not found in env file!"
              exit 1
            fi
          else
            echo "ERROR: No env file found!"
            echo "Please create $SOURCE_ENV_FILE with required variables."
            exit 1
          fi

      - name: Stop existing container
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          echo "Stopping existing container and related services..."

          # Î©îÏù∏ Ïï± Ïª®ÌÖåÏù¥ÎÑà Ï§ëÏßÄ
          sudo systemctl stop ${CONTAINER_NAME}.service 2>/dev/null || true
          sudo systemctl reset-failed ${CONTAINER_NAME}.service 2>/dev/null || true
          sudo podman stop ${CONTAINER_NAME} 2>/dev/null || true
          sudo podman rm -f ${CONTAINER_NAME} 2>/dev/null || true

          # dnsmasq ÌîÑÎ°úÏÑ∏Ïä§ Ï†ïÎ¶¨ (ÎÑ§Ìä∏ÏõåÌÅ¨ Î¨∏Ï†ú Î∞©ÏßÄ)
          echo "Cleaning up dnsmasq processes..."
          sudo pkill -9 dnsmasq 2>/dev/null || true
          sleep 2

          echo "Existing container stopped"

      - name: Reload systemd and start service
        id: deploy
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          echo "Deploying ${CONTAINER_NAME}..."

          sudo systemctl daemon-reload

          if ! sudo systemctl start ${CONTAINER_NAME}.service; then
            echo "Service failed to start!"
            echo ""
            echo "=== systemctl status ==="
            sudo systemctl status ${CONTAINER_NAME}.service --no-pager -l || true
            echo ""
            echo "=== journalctl logs ==="
            sudo journalctl -xeu ${CONTAINER_NAME}.service --no-pager -n 100 || true
            exit 1
          fi

          echo "Waiting for container to initialize..."
          sleep 15

      - name: Verify deployment
        id: verify
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          PORT="${{ steps.vars.outputs.port }}"
          MAX_RETRIES=15
          RETRY_COUNT=0

          echo "Container status:"
          sudo podman ps -a | grep ${CONTAINER_NAME} || true

          if ! sudo podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_NAME}$"; then
            echo "Container is not running!"
            echo "=== Container logs ==="
            sudo podman logs ${CONTAINER_NAME} 2>&1 | tail -100 || true
            echo "deploy_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi

          echo "Container ${CONTAINER_NAME} is running!"
          echo "Waiting for health check..."

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            sleep 3
            response=$(curl -sf -o /dev/null -w "%{http_code}" http://localhost:${PORT}/api/health 2>/dev/null || echo "000")
            if [ "$response" = "200" ]; then
              echo "Health check passed! (attempt $((RETRY_COUNT + 1)))"
              echo "deploy_success=true" >> $GITHUB_OUTPUT
              break
            fi
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "Health check attempt $RETRY_COUNT/$MAX_RETRIES (status: $response)"
          done

          if [ "$response" != "200" ]; then
            echo "Health check failed after $MAX_RETRIES attempts"
            echo "deploy_success=false" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Enable service on boot
        run: |
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"
          sudo systemctl enable ${CONTAINER_NAME}.service 2>/dev/null || true
          echo "Service enabled for auto-start"

      - name: Show deployment info
        if: always()
        run: |
          ENV="${{ steps.env.outputs.environment }}"
          PORT="${{ steps.vars.outputs.port }}"
          URL="${{ steps.vars.outputs.url }}"
          CONTAINER_NAME="${{ steps.vars.outputs.container_name }}"

          echo ""
          echo "=========================================="
          echo "üì¶ Deployment Summary"
          echo "=========================================="
          echo "Environment: ${ENV}"
          echo "Container: ${CONTAINER_NAME}"
          echo "Image: localhost/${{ env.APP_NAME }}:${{ steps.vars.outputs.image_tag }}"
          echo "Port: ${PORT}"
          echo "Commit: ${{ github.sha }}"
          echo "Branch: ${{ github.ref_name }}"
          echo ""
          echo "üåê URL: ${URL}"
          echo ""
          echo "=== Service Status ==="
          sudo systemctl is-active ${CONTAINER_NAME}.service || true
          echo ""
          echo "=== Running Containers ==="
          sudo podman ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "(NAMES|${{ env.APP_NAME }})" || true

      - name: Cleanup old images
        if: success()
        run: |
          echo "Cleaning up old images..."
          # ÏµúÏã† NÍ∞ú Ï†úÏô∏ÌïòÍ≥† ÏÇ≠Ï†ú
          sudo podman images localhost/${{ env.APP_NAME }} --format "{{.ID}} {{.CreatedAt}}" | \
            sort -k2 -r | tail -n +${{ env.MAX_IMAGE_RETENTION }} | awk '{print $1}' | \
            xargs -r sudo podman rmi 2>/dev/null || true
          sudo podman image prune -f 2>/dev/null || true
          echo "Cleanup complete!"

  # ============================================================================
  # Stage 4: Î°§Î∞± (Î∞∞Ìè¨ Ïã§Ìå® Ïãú)
  # ============================================================================
  rollback:
    name: Rollback on Failure
    runs-on: self-hosted
    needs: build-deploy
    if: failure() && needs.build-deploy.outputs.previous_image != ''

    steps:
      - name: Rollback to previous version
        run: |
          CONTAINER_NAME="${{ needs.build-deploy.outputs.container_name }}"
          PREVIOUS_IMAGE="${{ needs.build-deploy.outputs.previous_image }}"
          IMAGE_TAG="${{ needs.build-deploy.outputs.image_tag }}"

          echo "‚ö†Ô∏è Rolling back to previous version: $PREVIOUS_IMAGE"

          # Ïù¥Ï†Ñ Ïù¥ÎØ∏ÏßÄÎ°ú ÌÉúÍ∑∏ Î≥µÏõê
          sudo podman tag localhost/${{ env.APP_NAME }}:${PREVIOUS_IMAGE} localhost/${{ env.APP_NAME }}:${IMAGE_TAG}

          # ÏÑúÎπÑÏä§ Ïû¨ÏãúÏûë
          sudo systemctl restart ${CONTAINER_NAME}.service

          sleep 10

          # ÌôïÏù∏
          if sudo podman ps --format "{{.Names}}" | grep -q "^${CONTAINER_NAME}$"; then
            echo "‚úÖ Rollback successful!"
          else
            echo "‚ùå Rollback failed!"
            exit 1
          fi

  # ============================================================================
  # Stage 5: ÏïåÎ¶º
  # ============================================================================
  notify:
    name: Send Notification
    runs-on: self-hosted
    needs: [build-deploy, rollback]
    if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
      - name: Deployment Success Notification
        if: needs.build-deploy.result == 'success'
        run: |
          echo "‚úÖ Deployment successful!"
          echo "Environment: ${{ needs.build-deploy.outputs.environment }}"
          echo "URL: ${{ needs.build-deploy.outputs.url }}"
          echo "Commit: ${{ github.sha }}"

      - name: Rollback Notification
        if: needs.rollback.result == 'success'
        run: |
          echo "‚ö†Ô∏è Deployment failed and rolled back!"
          echo "Previous version restored: ${{ needs.build-deploy.outputs.previous_image }}"
          echo "Check logs at: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

      - name: Deployment Failure Notification
        if: needs.build-deploy.result == 'failure' && needs.rollback.result != 'success'
        run: |
          echo "‚ùå Deployment failed!"
          echo "Check logs at: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
